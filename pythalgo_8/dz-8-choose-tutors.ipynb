{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nimport random","metadata":{"execution":{"iopub.status.busy":"2022-07-08T23:57:35.036291Z","iopub.execute_input":"2022-07-08T23:57:35.036755Z","iopub.status.idle":"2022-07-08T23:57:36.372351Z","shell.execute_reply.started":"2022-07-08T23:57:35.036670Z","shell.execute_reply":"2022-07-08T23:57:36.371187Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/choose-tutors/train.csv\")\ntest_df = pd.read_csv(\"../input/choose-tutors/test.csv\")\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T23:57:40.382509Z","iopub.execute_input":"2022-07-08T23:57:40.382888Z","iopub.status.idle":"2022-07-08T23:57:40.488655Z","shell.execute_reply.started":"2022-07-08T23:57:40.382860Z","shell.execute_reply":"2022-07-08T23:57:40.487365Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Id   age  years_of_experience  lesson_price  qualification  physics  \\\n0   0  35.0                  0.0        2150.0            2.0      0.0   \n1   1  52.0                  2.0        1250.0            2.0      1.0   \n2   2  29.0                  3.0        1750.0            1.0      1.0   \n3   3  33.0                  3.0        1050.0            1.0      0.0   \n4   4  46.0                  3.0        2250.0            2.0      1.0   \n\n   chemistry  biology  english  geography  history  mean_exam_points  choose  \n0        0.0      0.0      0.0        0.0      0.0              74.0       0  \n1        0.0      1.0      0.0        0.0      1.0              57.0       1  \n2        0.0      0.0      0.0        0.0      0.0              66.0       0  \n3        0.0      0.0      0.0        0.0      0.0              66.0       1  \n4        0.0      0.0      0.0        0.0      0.0              73.0       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>age</th>\n      <th>years_of_experience</th>\n      <th>lesson_price</th>\n      <th>qualification</th>\n      <th>physics</th>\n      <th>chemistry</th>\n      <th>biology</th>\n      <th>english</th>\n      <th>geography</th>\n      <th>history</th>\n      <th>mean_exam_points</th>\n      <th>choose</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>35.0</td>\n      <td>0.0</td>\n      <td>2150.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>74.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>52.0</td>\n      <td>2.0</td>\n      <td>1250.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>57.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>29.0</td>\n      <td>3.0</td>\n      <td>1750.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>66.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>33.0</td>\n      <td>3.0</td>\n      <td>1050.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>66.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>46.0</td>\n      <td>3.0</td>\n      <td>2250.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>73.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class Node:\n    \"\"\"Класс узла\"\"\"\n    \n    def __init__(self, index, t, true_branch, false_branch):\n        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n        self.t = t  # значение порога\n        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле\n\nclass Leaf:\n    \"\"\"Класс терминального узла (листа)\"\"\"\n    \n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n        self.prediction = self.predict()\n        \n    def predict(self):\n        # подсчет количества объектов разных классов\n        classes = {}\n        for label in self.labels:\n            if label not in classes:\n                classes[label] = 0\n            classes[label] += 1\n        #  найдем класс, количество объектов которого будет максимальным в этом листе и вернем его    \n        prediction = max(classes, key=classes.get)\n        return prediction\n\nclass RandomForestClassifier():\n    \"\"\"Класс алгоритма RandomForestClassifier\"\"\"\n\n    @property\n    def forest_(self):\n        return self.forest\n    \n    @property\n    def n_trees_(self):\n        return self.n_trees\n\n    def __init__(self, n_trees = 1, max_depth=5, min_leaf=1, random_state=42):\n        self.n_trees = n_trees\n        self.random_state = random_state\n        self.max_depth = max_depth\n        self.min_leaf = min_leaf\n        self.forest = []\n\n    def bootstrap(self, X, y):\n        n_samples = X.shape[0]\n        np.random.seed(self.random_state)\n        \n        bootstrap = []\n        for i in range(self.n_trees):\n            b_data = np.zeros(X.shape)\n            b_labels = np.zeros(y.shape)\n            \n            for j in range(n_samples):\n                sample_index = np.random.randint(0, n_samples-1)\n                b_data[j] = X[sample_index]\n                b_labels[j] = y[sample_index]\n            bootstrap.append((b_data, b_labels))\n        \n        return bootstrap\n    \n    def subsample(self, len_sample):\n        # будем сохранять не сами признаки, а их индексы\n        sample_indexes = [i for i in range(len_sample)]\n        \n        len_subsample = int(np.sqrt(len_sample))\n        \n        subsample = []\n        np.random.shuffle(sample_indexes)\n        for _ in range(len_subsample):\n            subsample.append(sample_indexes.pop())\n        \n        return subsample\n    \n    def calc_criterion(self, y):\n        \"\"\"Расчет критерия информативности\"\"\"\n\n        #  подсчет количества объектов разных классов\n        classes = {}\n        for label in y:\n            if label not in classes:\n                classes[label] = 0\n            classes[label] += 1\n\n        # Расчет критерия Джини\n        impurity = 1\n        for label in classes:\n            p = classes[label] / len(y)\n            impurity -= p ** 2\n\n        return impurity\n    \n    def quality(self, left_labels, right_labels, current_criterion):\n        \"\"\"Расчет качества\"\"\"\n\n        # доля выбоки, ушедшая в левое поддерево\n        p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n        \n        return current_criterion - p * self.calc_criterion(left_labels) - (1 - p) * self.calc_criterion(right_labels)\n\n    @staticmethod\n    def split(X, y, index, t):\n        \"\"\"Разбиение датасета в узле\"\"\"\n\n        left = np.where(X[:, index] <= t)\n        right = np.where(X[:, index] > t)\n            \n        true_data = X[left]\n        false_data = X[right]\n        true_labels = y[left]\n        false_labels = y[right]\n            \n        return true_data, false_data, true_labels, false_labels\n\n    def find_best_split(self, X, y):\n        \"\"\"Нахождение наилучшего разбиения\"\"\"\n\n        current_criterion = self.calc_criterion(y)\n\n        best_quality = 0\n        best_t = None\n        best_index = None\n        \n        n_features = X.shape[1]\n        \n        # выбор индекса из подвыборки длиной sqrt(n_features)\n        subsample = self.subsample(n_features)\n        \n        for index in subsample:\n            # будем проверять только уникальные значения признака, исключая повторения\n            t_values = np.unique([row[index] for row in X])\n            \n            for t in t_values:\n                true_data, false_data, true_labels, false_labels = self.split(X, y, index, t)\n                #  пропускаем разбиения, в которых в узле объектов менее заданных в min_leaf\n                if len(true_data) < self.min_leaf or len(false_data) < self.min_leaf:\n                    continue\n                \n                current_quality = self.quality(true_labels, false_labels, current_criterion)\n                \n                #  выбираем порог, на котором получается максимальный прирост качества\n                if current_quality > best_quality:\n                    best_quality, best_t, best_index = current_quality, t, index\n\n        return best_quality, best_t, best_index\n\n    def tree(self, X, y):\n\n        def build_tree(X, y, **kwargs):\n            \"\"\"Построение дерева с помощью рекурсивной функции\"\"\"\n            \n            # ограничение по глубине дерева\n            kwargs['depth'] += 1\n            if kwargs['depth'] > self.max_depth:\n                return Leaf(X, y)\n\n            quality, t, index = self.find_best_split(X, y)\n\n            #  Базовый случай - прекращаем рекурсию, когда нет прироста качества\n            if quality == 0:\n                return Leaf(X, y)\n\n            true_data, false_data, true_labels, false_labels = self.split(X, y, index, t)\n\n            # Рекурсивно строим два поддерева\n            true_branch = build_tree(true_data, true_labels, depth=kwargs['depth'])\n            false_branch = build_tree(false_data, false_labels, depth=kwargs['depth'])\n            \n            # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n            return Node(index, t, true_branch, false_branch)\n    \n        return build_tree(X, y, depth=0)\n    \n    def predict(self, X, proba=False):\n        \"\"\"Предсказание голосованием деревьев \"\"\"\n        \n        def tree_predict(X, tree):\n            \"\"\"Функция формирования предсказания по выборке на одном дереве\"\"\"\n            \n            return [classify_object(obj, tree) for obj in X]\n        \n        def classify_object(obj, node):\n            \"\"\"Функция классификации отдельного объекта\"\"\"\n\n            #  Останавливаем рекурсию, если достигли листа\n            if isinstance(node, Leaf):\n                return node.prediction\n            \n            if obj[node.index] <= node.t:\n                return classify_object(obj, node.true_branch)\n            else:\n                return classify_object(obj, node.false_branch)\n        \n        # добавим предсказания всех деревьев в список\n        predictions = []\n        for tree in self.forest:\n            prediction = tree_predict(X, tree)\n            predictions.append(prediction)\n        \n        # сформируем список с предсказаниями для каждого объекта\n        predictions_per_object = list(zip(*predictions))\n        \n        answers = []\n        if proba is True:\n            for obj in predictions_per_object:\n                class_0 = 0\n                class_1 = 0\n                for itm in obj:\n                    if itm == 0:\n                        class_0 += 1\n                    else:\n                        class_1 += 1\n                probability = class_1 / (class_0 + class_1)\n                answers.append(probability)\n        else:\n            for obj in predictions_per_object:\n                predicted_class = max(set(obj), key=obj.count)\n                answers.append(predicted_class)\n        \n        return answers\n\n    def predict_proba(self, X):\n        \"\"\"Получение вероятности предсказания\"\"\"\n        \n        return self.predict(X, proba=True)\n    \n    def fit(self, X, y):\n        bootstrap = self.bootstrap(X, y)\n        \n        for b_data, b_labels in bootstrap:\n            self.forest.append(self.tree(b_data, b_labels))","metadata":{"execution":{"iopub.status.busy":"2022-07-08T23:57:44.671665Z","iopub.execute_input":"2022-07-08T23:57:44.672029Z","iopub.status.idle":"2022-07-08T23:57:44.725140Z","shell.execute_reply.started":"2022-07-08T23:57:44.672000Z","shell.execute_reply":"2022-07-08T23:57:44.723679Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def accuracy_metric(actual, predicted):\n    correct = 0\n    for i in range(len(actual)):\n        if actual[i] == predicted[i]:\n            correct += 1\n    return correct / float(len(actual)) * 100.0\n\n\ndef std_func(x):    \n    return (x - x.mean()) / x.std()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T23:57:52.635789Z","iopub.execute_input":"2022-07-08T23:57:52.636163Z","iopub.status.idle":"2022-07-08T23:57:52.645123Z","shell.execute_reply.started":"2022-07-08T23:57:52.636124Z","shell.execute_reply":"2022-07-08T23:57:52.643063Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def results(model, X_train, X_test, y_train, y_test):\n\n    y_train_pred = model.predict(X_train)\n    y_test_pred = model.predict(X_test)\n    \n    print('Train')\n    print(f'Accuracy: {accuracy_metric(y_train, y_train_pred):.3f}')\n    \n    print('\\nTest')\n    print(f'Accuracy: {accuracy_metric(y_test, y_test_pred):.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T23:57:55.767754Z","iopub.execute_input":"2022-07-08T23:57:55.768436Z","iopub.status.idle":"2022-07-08T23:57:55.774311Z","shell.execute_reply.started":"2022-07-08T23:57:55.768404Z","shell.execute_reply":"2022-07-08T23:57:55.773201Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"np_train = train_df.to_numpy()\n\nX = std_func(np_train[:,1:12])\ny = np_train[:,-1].astype(int)\n\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    shuffle=True,\n                                                    test_size=0.25,\n                                                    random_state=0,\n                                                    stratify=y)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T23:57:57.089076Z","iopub.execute_input":"2022-07-08T23:57:57.089406Z","iopub.status.idle":"2022-07-08T23:57:57.114581Z","shell.execute_reply.started":"2022-07-08T23:57:57.089383Z","shell.execute_reply":"2022-07-08T23:57:57.113770Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"clf = RandomForestClassifier(\n    n_trees=50,\n    max_depth=7,\n    min_leaf=1,\n    random_state=0,\n)\nclf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T00:01:47.725551Z","iopub.execute_input":"2022-07-09T00:01:47.727380Z","iopub.status.idle":"2022-07-09T00:03:23.984514Z","shell.execute_reply.started":"2022-07-09T00:01:47.727321Z","shell.execute_reply":"2022-07-09T00:03:23.983348Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"results(clf, X_train, X_test, y_train, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T00:04:21.981512Z","iopub.execute_input":"2022-07-09T00:04:21.981867Z","iopub.status.idle":"2022-07-09T00:04:24.916803Z","shell.execute_reply.started":"2022-07-09T00:04:21.981840Z","shell.execute_reply":"2022-07-09T00:04:24.916024Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Train\nAccuracy: 89.720\n\nTest\nAccuracy: 89.480\n","output_type":"stream"}]},{"cell_type":"code","source":"np_test = test_df.to_numpy()\nX_test = std_func(np_test[:,1:12])\npredictions = clf.predict_proba(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T00:04:35.006138Z","iopub.execute_input":"2022-07-09T00:04:35.006539Z","iopub.status.idle":"2022-07-09T00:04:36.543427Z","shell.execute_reply.started":"2022-07-09T00:04:35.006511Z","shell.execute_reply":"2022-07-09T00:04:36.542402Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv('../input/choose-tutors/submission_example.csv')\nsubmit.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T00:04:38.110278Z","iopub.execute_input":"2022-07-09T00:04:38.110932Z","iopub.status.idle":"2022-07-09T00:04:38.135493Z","shell.execute_reply.started":"2022-07-09T00:04:38.110901Z","shell.execute_reply":"2022-07-09T00:04:38.134647Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"      Id  choose\n0  10000     0.5\n1  10001     0.5\n2  10002     0.5\n3  10003     0.5\n4  10004     0.5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>choose</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10000</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10001</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10002</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10003</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10004</td>\n      <td>0.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submit['choose'] = predictions\nsubmit.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-09T00:04:40.324130Z","iopub.execute_input":"2022-07-09T00:04:40.324736Z","iopub.status.idle":"2022-07-09T00:04:40.341858Z","shell.execute_reply.started":"2022-07-09T00:04:40.324702Z","shell.execute_reply":"2022-07-09T00:04:40.340550Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"      Id  choose\n0  10000    0.24\n1  10001    0.46\n2  10002    0.24\n3  10003    0.24\n4  10004    0.40","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>choose</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10000</td>\n      <td>0.24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10001</td>\n      <td>0.46</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10002</td>\n      <td>0.24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10003</td>\n      <td>0.24</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10004</td>\n      <td>0.40</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submit.to_csv('rf_submit.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-09T00:04:45.803114Z","iopub.execute_input":"2022-07-09T00:04:45.803492Z","iopub.status.idle":"2022-07-09T00:04:45.834308Z","shell.execute_reply.started":"2022-07-09T00:04:45.803462Z","shell.execute_reply":"2022-07-09T00:04:45.833331Z"},"trusted":true},"execution_count":15,"outputs":[]}]}